# Backend Environment Variables

# Server Configuration
API_HOST=127.0.0.1
API_PORT=8080

# Database Configuration
# Required when running outside docker-compose
DATABASE_URL=

# Environment Settings
ENVIRONMENT=development
DEBUG=True

# Authentication Settings
# Select 'none' for single-user mode or 'supabase' for multi-user
AUTH_PROVIDER=supabase
# Session middleware secret key (change in production)
SECRET_KEY=your-secret-key-change-in-production-auth-sessions-development
# Supabase configuration (required when AUTH_PROVIDER=supabase)
SUPABASE_URL=https://sznfaqmsmdwmafnrrt.supabase.co
SUPABASE_PUBLISHABLE_KEY=sb_pubjA9tdCyW81VFSDQ_Vxh4kahw
SUPABASE_SECRET_KEY=sb_secret_QMKnBzJa4tp2R9_-hQ
# Optional: Not used by backend token validation currently, provided for completeness
SUPABASE_JWT_SECRET=97ceaf72-1066-429f-9c61-6272537eec55

# Storage Settings
# STORAGE_PROVIDER can be 'local' or 'r2'
STORAGE_PROVIDER=local
LOCAL_STORAGE_PATH=uploads
# Cloudflare R2 configuration (required when STORAGE_PROVIDER=r2)
R2_ACCOUNT_ID=
R2_ACCESS_KEY_ID=
R2_SECRET_ACCESS_KEY=
R2_BUCKET_NAME=
R2_REGION=auto

# Code Execution (E2B)
# E2B API key (SDK reads this env)
E2B_API_KEY=

# Provider API Keys (set as needed for LiteLLM)
OLLAMA_API_BASE=
OPENAI_API_KEY=
OPENROUTER_API_KEY=
ANTHROPIC_API_KEY=
GEMINI_API_KEY=
DEEPSEEK_API_KEY=
HUGGINGFACE_API_KEY=

# AI Model Configuration
# Required: primary model used across the app
# Example: openai/gpt-4o-mini, anthropic/claude-3-5-sonnet, ollama/llama3
PRIMARY_LLM_MODEL=

# RAG Embeddings (required if using RAG)
# Example: openai/text-embedding-3-small, ollama/nomic-embed-text
RAG_EMBEDDING_MODEL=
# Required: dimension must match the embedding model
# Example: 1536 for text-embedding-3-small, 768 for nomic-embed-text
RAG_EMBEDDING_OUTPUT_DIM=

# AI Infrastructure Settings (reliability/performance)
# Timeout for AI API requests in seconds (30=dev, 60=prod, 120=heavy models)
AI_REQUEST_TIMEOUT=60

# Mem0 Memory System Settings
# If MEMORY_* not set, falls back to PRIMARY_LLM_MODEL and RAG_* where applicable.
# Note: mem0 embedder currently supports OpenAI only.
# Example: openai/text-embedding-3-small and 1536
MEMORY_LLM_MODEL=
MEMORY_EMBEDDING_MODEL=
MEMORY_EMBEDDING_OUTPUT_DIM=
